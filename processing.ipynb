{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd093861e993bc647e90e5e9bd3353ecaf3d7bebc109bc4c78b5428fd668748908c",
   "display_name": "Python 3.8.2 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TEST_LOCATION = \"./COMP30027_2021_Project2_datasets/recipe_test.csv\"\n",
    "TRAIN_LOCATION = \"./COMP30027_2021_Project2_datasets/recipe_train.csv\"\n",
    "\n",
    "def preprocess(csv_location: str) -> pd.DataFrame:\n",
    "    # Change 9999 to np.nan when reading in the data\n",
    "    data = pd.read_csv(csv_location, header = 0) \n",
    "    return data\n",
    "\n",
    "def create_csv_output(file_name: str, result: np.ndarray):\n",
    "    output = pd.DataFrame({\"duration_label\": result})\n",
    "    output.index += 1\n",
    "    output.to_csv(file_name + \".csv\", index_label = \"id\")\n",
    "\n",
    "def get_training(train_loc: str):\n",
    "    train = preprocess(train_loc)\n",
    "    X = train.iloc[:, :-1]\n",
    "    y = train.iloc[:, -1]\n",
    "    return (X, y)\n",
    "\n",
    "def convert_to_proper_output(file_name: str):\n",
    "    old = pd.read_csv(file_name + \".csv\", header = 0)\n",
    "    old.index += 1\n",
    "    old.to_csv(file_name + \"-new.csv\", index_label = \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\mihai\\AppData\\Local\\Programs\\Python\\Python38-32\\Lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.3 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "---vec---\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 1976)\t1\n",
      "  (0, 2916)\t1\n",
      "  (0, 3871)\t1\n",
      "  (0, 4437)\t1\n",
      "  (0, 8202)\t1\n",
      "  (0, 9458)\t1\n",
      "  (0, 10597)\t1\n",
      "---vec50---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "            0         1         2         3         4         5         6   \\\n",
      "0    -0.074475  0.043355 -0.200122  0.562771  0.051261 -0.283168  0.023642   \n",
      "1    -0.083797 -0.119397  0.055886  0.459259 -0.129858  0.275230 -0.274989   \n",
      "2    -0.188450  0.037819 -0.098069 -0.140659 -0.056237 -0.074347  0.172098   \n",
      "3     0.039180  0.458914  0.201800  0.052737 -0.095670  0.231523  0.064118   \n",
      "4     0.235192 -0.201566 -0.543494 -0.418995 -0.186713  0.058639 -0.241507   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  0.083350 -0.252363  0.080970 -0.064834 -0.209142 -0.106377  0.105602   \n",
      "9996 -0.147893  0.043239  0.147160  0.014753  0.154295 -0.234711  0.132267   \n",
      "9997 -0.471655 -0.206248 -0.141278  0.144359  0.111215 -0.557390  0.170998   \n",
      "9998 -0.293525 -0.263556  0.408079 -0.058368 -0.309496 -0.377240  0.036279   \n",
      "9999  0.371551  0.214871  0.145509 -0.184968 -0.082843 -0.001567 -0.150924   \n",
      "\n",
      "            7         8         9   ...        40        41        42  \\\n",
      "0     0.206712 -0.420130  0.085731  ... -0.117237 -0.171444 -0.358693   \n",
      "1     0.099745 -0.486215  0.059932  ... -0.215473  0.007761  0.039201   \n",
      "2     0.102223 -0.093355  0.156367  ... -0.033779  0.075194  0.035581   \n",
      "3    -0.170139 -0.197386 -0.235173  ... -0.068196 -0.072971  0.065977   \n",
      "4     0.522636  0.674384 -0.038818  ... -0.017066  0.471566  0.354726   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "9995  0.052384 -0.242857  0.377072  ...  0.044255  0.196485  0.040218   \n",
      "9996  0.157129 -0.030288  0.100899  ...  0.227806  0.076100  0.046893   \n",
      "9997  0.311999  0.114766 -1.068103  ... -0.248815 -0.201303  0.496591   \n",
      "9998 -0.864266 -0.033658 -0.930044  ...  0.145365  0.035339 -0.193746   \n",
      "9999 -0.050700 -0.053492 -0.026814  ...  0.270633 -0.037506  0.129944   \n",
      "\n",
      "            43        44        45        46        47        48        49  \n",
      "0    -0.029650  0.125260 -0.010392 -0.135896 -0.145616  0.138046 -0.273710  \n",
      "1     0.447972 -0.157040  0.073286  0.121142 -0.216030  0.088260 -0.132940  \n",
      "2    -0.090499  0.136191 -0.039299 -0.154364 -0.019948 -0.141453 -0.010379  \n",
      "3    -0.451966 -0.336528  0.529605  0.076887 -0.285775 -0.824646  0.387724  \n",
      "4    -0.121142 -0.134447 -0.014948 -0.174682 -0.235580  0.053757  0.010975  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "9995  0.230291 -0.103667 -0.003117  0.003879 -0.194190 -0.073191  0.263025  \n",
      "9996  0.114263 -0.176960 -0.173696 -0.155935  0.154816 -0.046829 -0.087984  \n",
      "9997 -0.323045  0.013506  0.503874  0.203486  0.163391 -0.189195 -0.359226  \n",
      "9998 -0.231916  0.504800 -0.132571  0.117938 -0.263222  0.551820 -0.145547  \n",
      "9999 -0.366035 -0.381109  0.283413  0.252976 -0.337538  0.192992  0.016365  \n",
      "\n",
      "[10000 rows x 50 columns]\n",
      "---vec100---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "            0         1         2         3         4         5         6   \\\n",
      "0     0.019355  0.035026 -0.239034  0.372411  0.014897 -0.380068  0.322821   \n",
      "1     0.127224 -0.208422  0.035887  0.174384  0.030709 -0.642608 -0.153524   \n",
      "2     0.033923  0.072421 -0.037787 -0.149716 -0.037092  0.134167 -0.085270   \n",
      "3    -0.231206 -0.216044 -0.092498 -0.242702  0.579030  0.166147  0.162703   \n",
      "4    -0.006693  0.358688  0.624302 -0.179588 -0.666471  0.177925  0.315240   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "9995 -0.227954  0.115526  0.191929 -0.047599 -0.129791 -0.049639 -0.073601   \n",
      "9996 -0.050330  0.113638 -0.101167  0.031597 -0.234313 -0.013953 -0.011550   \n",
      "9997  0.020293 -0.006870  0.198684  0.088847  0.078037  0.503947  0.078114   \n",
      "9998  0.110554  0.131628 -0.026879  0.126497  0.350560 -0.184504  0.270354   \n",
      "9999  0.063889  0.161313  0.390326 -0.045107  0.062611 -0.175878  0.044192   \n",
      "\n",
      "            7         8         9   ...        90        91        92  \\\n",
      "0    -0.041233  0.027351  0.268096  ... -0.161969  0.103835  0.168672   \n",
      "1     0.024475  0.074357 -0.227293  ...  0.331851 -0.248568 -0.379277   \n",
      "2     0.043067  0.100368 -0.093392  ... -0.150206  0.086766 -0.052903   \n",
      "3     0.166989  0.203838  0.227461  ... -0.024456  0.111326  0.232295   \n",
      "4    -0.388413 -0.378578  0.378191  ...  0.289387  0.005371  0.045376   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "9995 -0.266990 -0.111118  0.112659  ... -0.172019  0.451772 -0.124413   \n",
      "9996  0.009274 -0.005019 -0.194041  ...  0.025233 -0.012514 -0.046232   \n",
      "9997 -0.097593 -0.342502  0.170830  ... -0.243409 -0.308416  0.164236   \n",
      "9998 -0.309724  0.208833  0.831496  ...  0.139237  0.111421  0.491716   \n",
      "9999  0.064269  0.204239  0.451139  ...  0.154141  0.232273 -0.015254   \n",
      "\n",
      "            93        94        95        96        97        98        99  \n",
      "0    -0.218751 -0.008702 -0.139268  0.110090 -0.098235  0.190759  0.145743  \n",
      "1    -0.038513 -0.189411  0.000961 -0.089637 -0.126970  0.176501 -0.097011  \n",
      "2     0.072364  0.003324  0.020976 -0.242271 -0.050635 -0.000903  0.033780  \n",
      "3     0.175071  0.115605 -0.050817 -0.260729 -0.070575 -0.172197 -0.038602  \n",
      "4     0.072623  0.268764 -0.427195  0.164267  0.026591 -0.557535  0.192671  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "9995  0.049769 -0.317411  0.115550 -0.287805  0.127554  0.082861  0.190803  \n",
      "9996  0.028400 -0.151081 -0.060349 -0.084223 -0.001365  0.059377  0.091138  \n",
      "9997 -0.079899  0.243051 -0.137315 -0.163180 -0.179635  0.046289  0.237684  \n",
      "9998  0.199077 -0.380109  0.173687  0.326915 -0.012889 -0.239455 -0.340002  \n",
      "9999 -0.269724 -0.024895 -0.118419  0.095468  0.225772  0.387224 -0.225285  \n",
      "\n",
      "[10000 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "#Loading in the datasets within the zip files based on steps in README\n",
    "import pickle\n",
    "\n",
    "BASE_LOCATION = \"./COMP30027_2021_Project2_datasets/\"\n",
    "COUNT_VEC_LOCATION = BASE_LOCATION + \"recipe_text_features_countvec/\"\n",
    "DOC2VEC50_VEC_LOCATION = BASE_LOCATION + \"recipe_text_features_doc2vec50/\"\n",
    "DOC2VEC100_VEC_LOCATION = BASE_LOCATION + \"recipe_text_features_doc2vec100/\"\n",
    "\n",
    "#countvecs are essentially a one-hot-encoding of the most popular words.\n",
    "train_name_countvec = pickle.load(open(COUNT_VEC_LOCATION + \"train_name_countvectorizer.pkl\", \"rb\"))\n",
    "train_ingr_countvec = pickle.load(open(COUNT_VEC_LOCATION + \"train_ingr_countvectorizer.pkl\", \"rb\"))\n",
    "train_steps_countvec = pickle.load(open(COUNT_VEC_LOCATION + \"train_steps_countvectorizer.pkl\", \"rb\"))\n",
    "\n",
    "#bag-of-word sparse matrices. Similar to one-hot-encoding but for all words.\n",
    "#column = word occurence, row = individual instance\n",
    "train_name_vec = scipy.sparse.load_npz(COUNT_VEC_LOCATION + 'train_name_vec.npz')\n",
    "train_ingr_vec = scipy.sparse.load_npz(COUNT_VEC_LOCATION + 'train_ingr_vec.npz')\n",
    "train_steps_vec = scipy.sparse.load_npz(COUNT_VEC_LOCATION + 'train_steps_vec.npz')\n",
    "\n",
    "test_name_vec = scipy.sparse.load_npz(COUNT_VEC_LOCATION + 'test_name_vec.npz')\n",
    "test_ingr_vec = scipy.sparse.load_npz(COUNT_VEC_LOCATION + 'test_ingr_vec.npz')\n",
    "test_steps_vec = scipy.sparse.load_npz(COUNT_VEC_LOCATION + 'test_steps_vec.npz')\n",
    "\n",
    "#Doc2Vec representation with 50 features. Think of them as 50 dimensional vectors representing the words/phrases\n",
    "test_name_vec50 = pd.read_csv(DOC2VEC50_VEC_LOCATION + \"test_name_doc2vec50.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_ingr_vec50 = pd.read_csv(DOC2VEC50_VEC_LOCATION + \"test_ingr_doc2vec50.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_steps_vec50 = pd.read_csv(DOC2VEC50_VEC_LOCATION + \"test_steps_doc2vec50.csv\", index_col = False, delimiter = ',', header=None)\n",
    "\n",
    "train_name_vec50 = pd.read_csv(DOC2VEC50_VEC_LOCATION + \"train_name_doc2vec50.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_ingr_vec50 = pd.read_csv(DOC2VEC50_VEC_LOCATION + \"train_ingr_doc2vec50.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_steps_vec50 = pd.read_csv(DOC2VEC50_VEC_LOCATION + \"train_steps_doc2vec50.csv\", index_col = False, delimiter = ',', header=None)\n",
    "\n",
    "#Doc2Vec representation with 100 features. Think of them as 100 dimensional vectors representing the words/phrases\n",
    "test_name_vec100 = pd.read_csv(DOC2VEC100_VEC_LOCATION + \"test_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_ingr_vec100 = pd.read_csv(DOC2VEC100_VEC_LOCATION + \"test_ingr_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_steps_vec100 = pd.read_csv(DOC2VEC100_VEC_LOCATION + \"test_steps_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "\n",
    "train_name_vec100 = pd.read_csv(DOC2VEC100_VEC_LOCATION + \"train_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_ingr_vec100 = pd.read_csv(DOC2VEC100_VEC_LOCATION + \"train_ingr_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_steps_vec100 = pd.read_csv(DOC2VEC100_VEC_LOCATION + \"train_steps_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "\"\"\"\n",
    "print(\"---countvec---\")\n",
    "print(train_name_countvec.get_feature_names())\n",
    "\"\"\"\n",
    "print(\"---vec---\")\n",
    "print(type(train_name_vec))\n",
    "print(train_name_vec[0, :]) #words corresponding to an individual instance\n",
    "#print(train_name_vec)\n",
    "\n",
    "print(\"---vec50---\")\n",
    "print(type(test_name_vec50))\n",
    "print(test_name_vec50)\n",
    "print(\"---vec100---\")\n",
    "print(type(test_name_vec100))\n",
    "print(test_name_vec100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero-R classifier\n",
    "from sklearn import dummy\n",
    "\n",
    "(X, y) = get_training(TRAIN_LOCATION)\n",
    "zero_r_clf = dummy.DummyClassifier(strategy = \"most_frequent\")\n",
    "zero_r_clf.fit(X, y)\n",
    "\n",
    "test = preprocess(TEST_LOCATION)\n",
    "output = zero_r_clf.predict(test)\n",
    "create_csv_output(\"zero-r/zero-r\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "from sklearn import svm\n",
    "\n",
    "(X, y) = get_training(TRAIN_LOCATION)\n",
    "X = X.to_numpy()[:, 1:3]\n",
    "y = y.to_numpy()\n",
    "\n",
    "C = 1.0  # SVM regularization parameter\n",
    "\n",
    "models = (svm.SVC(kernel='linear', C=C),\n",
    "          svm.LinearSVC(C=C, max_iter=10000),\n",
    "          svm.SVC(kernel='rbf', gamma='auto', C=C))\n",
    "\n",
    "models = (clf.fit(X, y) for clf in models)\n",
    "\n",
    "titles = ('SVC-with-linear-kernel',\n",
    "          'LinearSVC-linear-kernel',\n",
    "          'SVC-with-RBF-kernel')\n",
    "\n",
    "X_test = preprocess(TEST_LOCATION)\n",
    "X_test = X_test.to_numpy()[:, 1:3]\n",
    "\n",
    "for (title, clf) in zip(titles, models):\n",
    "    print(\"predicting \" + title)\n",
    "    output = clf.predict(X_test)\n",
    "    print(\"creating output csv\")\n",
    "    create_csv_output(\"SVC/\" + title, output) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nfor (title, clf) in zip(titles, models):\\n    print(\"predicting \" + title)\\n    output = clf.predict(X_test)\\n    print(\"creating output csv\")\\n    create_csv_output(\"SVC-adv/\" + title, output) \\n'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#SVC with \n",
    "from sklearn import svm\n",
    "\n",
    "(X, y) = get_training(TRAIN_LOCATION)\n",
    "X = X.loc[:, [\"n_steps\", \"n_ingredients\"]]\n",
    "y = y.to_numpy()\n",
    "\n",
    "temp_steps_vec50 = train_ingr_vec50.copy()\n",
    "temp_steps_vec50.columns = [str(label) + \"_steps\" for label in temp_steps_vec50.columns]\n",
    "\n",
    "X = pd.concat([X, temp_steps_vec50], axis = 1, join = 'inner')\n",
    "\n",
    "C = 1.0  # SVM regularization parameter\n",
    "'''\n",
    "models = (svm.SVC(kernel='linear', C=C),\n",
    "          svm.LinearSVC(C=C, max_iter=10000),\n",
    "          svm.SVC(kernel='rbf', gamma='auto', C=C))\n",
    "\n",
    "models = (clf.fit(X, y) for clf in models)\n",
    "\n",
    "titles = ('SVC-with-linear-kernel',\n",
    "          'LinearSVC-linear-kernel',\n",
    "          'SVC-with-RBF-kernel')\n",
    "'''\n",
    "\n",
    "model = svm.SVC(kernel='rbf', gamma='auto', C=C)\n",
    "model = model.fit(X, y)\n",
    "title = 'SVC-with-RBF-kernel'\n",
    "\n",
    "X_test = preprocess(TEST_LOCATION)\n",
    "X_test = X_test.loc[:, [\"n_steps\", \"n_ingredients\"]]\n",
    "\n",
    "temp_steps_vec50 = test_ingr_vec50.copy()\n",
    "temp_steps_vec50.columns = [str(label) + \"_steps\" for label in temp_steps_vec50.columns]\n",
    "\n",
    "X_test = pd.concat([X_test, temp_steps_vec50], axis = 1, join = 'inner')\n",
    "\n",
    "output = model.predict(X_test)\n",
    "create_csv_output(\"SVC-adv/\" + title, output) \n",
    "\"\"\"\n",
    "for (title, clf) in zip(titles, models):\n",
    "    print(\"predicting \" + title)\n",
    "    output = clf.predict(X_test)\n",
    "    print(\"creating output csv\")\n",
    "    create_csv_output(\"SVC-adv/\" + title, output) \n",
    "\"\"\""
   ]
  }
 ]
}